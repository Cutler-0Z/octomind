embedding_provider = "FastEmbed"
jina_api_key = "your-jina-api-key"

[fastembed]
code_model = "all-MiniLM-L6-v2"
text_model = "all-MiniLM-L6-v2"

[jina]
code_model = "jina-embeddings-v2-base-code"
text_model = "jina-embeddings-v3"

[openrouter]
model = "anthropic/claude-sonnet-4"
api_key = "your-openrouter-api-key"
enable_layers = true
debug = true
query_processor_model = "openai/gpt-4.1-nano"
context_generator_model = "google/gemini-2.5-flash-preview"
reducer_model = "openai/o4-mini"
mcp_response_warning_threshold = 10000
max_request_tokens_threshold = 12000
enable_auto_truncation = false
cache_tokens_pct_threshold = 50

[openrouter.pricing]
input_price = 0.000001
output_price = 0.000002

[mcp]
enabled = true
providers = ["core"]
servers = []

# Layer configurations
[[layers]]
name = "query_processor"
enabled = true
model = "openai/gpt-4.1-mini"
system_prompt = "Custom system prompt for query processing layer. You analyze the user's request and clarify it.%{CONTEXT}"
temperature = 0.1
enable_tools = false
allowed_tools = []
input_mode = "Last"

[[layers]]
name = "context_generator"
enabled = true
model = "google/gemini-2.5-flash-preview"
system_prompt = "Custom system prompt for context generator. You gather context for the task. %{GIT_STATUS} %{README}"
temperature = 0.2
enable_tools = true
allowed_tools = ["core", "text_editor", "list_files"]
input_mode = "Last"

[[layers]]
name = "developer"
enabled = true
model = "anthropic/claude-sonnet-4"
system_prompt = "Custom system prompt for developer. You implement the solution based on context provided."
temperature = 0.3
enable_tools = true
allowed_tools = []
input_mode = "All"

[[layers]]
name = "reducer"
enabled = false
model = "openai/o4-mini"
system_prompt = "Custom system prompt for reducer. You optimize and summarize context."
temperature = 0.2
enable_tools = false
allowed_tools = []
input_mode = "Summary"
